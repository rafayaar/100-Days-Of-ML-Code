{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31b6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import os\n",
    "print(os.listdir(r\"C:\\Users\\HP\\Downloads\\archive (2)\\2015_BOE_Chiu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = r\"C:\\Users\\HP\\Downloads\\archive (2)\\2015_BOE_Chiu\\2015_BOE_Chiu\"\n",
    "subject_path = [os.path.join(input_path, 'Subject_0{}.mat'.format(i)) for i in range(1, 10)] + [os.path.join(input_path, 'Subject_10.mat')]\n",
    "\n",
    "data_indexes = [10, 15, 20, 25, 28, 30, 32, 35, 40, 45, 50]\n",
    "\n",
    "width = 284\n",
    "height = 284\n",
    "width_out = 196\n",
    "height_out = 196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(subject_path[0])\n",
    "img_tensor = mat['images']\n",
    "manual_fluid_tensor_1 = mat['manualFluid1']\n",
    "\n",
    "img_array = np.transpose(img_tensor, (2, 0, 1))\n",
    "manual_fluid_array = np.transpose(manual_fluid_tensor_1, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cca70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_array[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bad4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(manual_fluid_array[25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec8b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresh(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "thresh = np.vectorize(thresh, otypes=[np.float])\n",
    "\n",
    "def create_dataset(paths):\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    for path in tqdm(paths):\n",
    "        mat = scipy.io.loadmat(path)\n",
    "        img_tensor = mat['images']\n",
    "        fluid_tensor = mat['manualFluid1']\n",
    "        \n",
    "        img_array = np.transpose(img_tensor, (2, 0 ,1)) / 255\n",
    "        img_array = resize(img_array, (img_array.shape[0], width, height))\n",
    "        fluid_array = np.transpose(fluid_tensor, (2, 0 ,1))\n",
    "        fluid_array = thresh(fluid_array)\n",
    "        fluid_array  = resize(fluid_array, (fluid_array .shape[0], width_out, height_out))\n",
    "\n",
    "        for idx in data_indexes:\n",
    "            x += [np.expand_dims(img_array[idx], 0)]\n",
    "            y += [np.expand_dims(fluid_array[idx], 0)]\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "x_train, y_train = create_dataset(subject_path[:9])\n",
    "x_val, y_val = create_dataset(subject_path[9:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd27e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282e4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from tqdm import trange\n",
    "from time import sleep\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a73911",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 9\n",
    "epochs = 1000\n",
    "epoch_lapse = 50\n",
    "threshold = 0.5\n",
    "sample_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e943c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                )\n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "                    )\n",
    "            return  block\n",
    "    \n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    )\n",
    "            return  block\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(UNet, self).__init__()\n",
    "        #Encode\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = torch.nn.Sequential(\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=256, out_channels=512),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.BatchNorm2d(512),\n",
    "                            torch.nn.Conv2d(kernel_size=3, in_channels=512, out_channels=512),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.BatchNorm2d(512),\n",
    "                            torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "                            )\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "        \n",
    "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        \n",
    "        bottleneck1 = self.bottleneck(encode_pool3)\n",
    "        \n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)\n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        final_layer = self.final_layer(decode_block1)\n",
    "        return  final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3997bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, labels, optimizer, criterion):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = unet(inputs)\n",
    "    outputs = outputs.permute(0, 2, 3, 1)\n",
    "    outputs = outputs.resize(batch_size*width_out*height_out, 2)\n",
    "    labels = labels.resize(batch_size*width_out*height_out)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab91ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "unet = UNet(in_channel=1,out_channel=2)\n",
    "if use_gpu:\n",
    "    unet = unet.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(unet.parameters(), lr = 0.01, momentum=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a7d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_loss(x_val, y_val):\n",
    "    x_val = torch.from_numpy(x_val).float()\n",
    "    y_val = torch.from_numpy(y_val).long()\n",
    "    if use_gpu:\n",
    "        x_val = x_val.cuda()\n",
    "        y_val = y_val.cuda()\n",
    "    m = x_val.shape[0]\n",
    "    outputs = unet(x_val)\n",
    "    outputs = outputs.permute(0, 2, 3, 1)\n",
    "    outputs = outputs.resize(m*width_out*height_out, 2)\n",
    "    labels = y_val.resize(m*width_out*height_out)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_iter = np.ceil(x_train.shape[0] / batch_size).astype(int)\n",
    "t = trange(epochs, leave=True)\n",
    "for _ in t:\n",
    "    total_loss = 0\n",
    "    for i in range(epoch_iter):\n",
    "        batch_train_x = torch.from_numpy(x_train[i * batch_size : (i + 1) * batch_size]).float()\n",
    "        batch_train_y = torch.from_numpy(y_train[i * batch_size : (i + 1) * batch_size]).long()\n",
    "        if use_gpu:\n",
    "            batch_train_x = batch_train_x.cuda()\n",
    "            batch_train_y = batch_train_y.cuda()\n",
    "        batch_loss = train_step(batch_train_x , batch_train_y, optimizer, criterion)\n",
    "        total_loss += batch_loss\n",
    "    if (_+1) % epoch_lapse == 0:\n",
    "        val_loss = get_val_loss(x_val, y_val)\n",
    "        print(f\"Total loss in epoch {_+1} : {total_loss / epoch_iter} and validation loss : {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb2995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_examples(datax, datay, num_examples=3):\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(18,4*num_examples))\n",
    "    m = datax.shape[0]\n",
    "    for row_num in range(num_examples):\n",
    "        image_indx = np.random.randint(m)\n",
    "        image_arr = unet(torch.from_numpy(datax[image_indx:image_indx+1]).float().cuda()).squeeze(0).detach().cpu().numpy()\n",
    "        ax[row_num][0].imshow(np.transpose(datax[image_indx], (1,2,0))[:,:,0])\n",
    "        ax[row_num][0].set_title(\"Orignal Image\")\n",
    "        ax[row_num][1].imshow(np.transpose(image_arr, (1,2,0))[:,:,0])\n",
    "        ax[row_num][1].set_title(\"Segmented Image\")\n",
    "        ax[row_num][2].imshow(image_arr.argmax(0))\n",
    "        ax[row_num][2].set_title(\"Segmented Image localization\")\n",
    "        ax[row_num][3].imshow(np.transpose(datay[image_indx], (1,2,0))[:,:,0])\n",
    "        ax[row_num][3].set_title(\"Target image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07867de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b09d588",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_examples(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99161cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(unet.state_dict(), 'unet.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
