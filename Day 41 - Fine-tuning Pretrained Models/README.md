## Day 41 - Fine-Tuning Pretrained Models

- This code fine-tunes a BERT model for text classification with three classes (negative, neutral, and positive) using a small example dataset.

- It implements a basic training loop with three epochs, monitoring validation loss and accuracy.

- The model is saved after training, providing a foundation for more advanced NLP tasks with fine-tuned BERT embeddings.